{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34a75ba3",
      "metadata": {
        "id": "34a75ba3"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13837a43",
      "metadata": {
        "id": "13837a43"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96c26b31",
      "metadata": {
        "id": "96c26b31"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import linalg as LA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8d88d0",
      "metadata": {
        "id": "3c8d88d0",
        "outputId": "6e543e91-bd17-4833-fcd2-99bcefd3f21e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(x) =  0.0\n",
            "Vax(x) =  1.0\n"
          ]
        }
      ],
      "source": [
        "'''probabilidades: 1 variable aleatoria \"x\"'''\n",
        "\n",
        "x0 = -1.\n",
        "x1 = 1.\n",
        "\n",
        "p0 = 0.5\n",
        "p1 = 1 - p0\n",
        "\n",
        "Ex = p0*x0 + p1*x1\n",
        "print(\"E(x) = \", Ex)\n",
        "Exx = p0*x0**2 + p1*x1**2\n",
        "Vx = Exx - Ex**2\n",
        "print(\"Vax(x) = \", Vx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47952021",
      "metadata": {
        "id": "47952021",
        "outputId": "2f57d8de-4d91-4172-f6d9-d062456e0e20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datos empiricos de x = \n",
            " [[-1.]\n",
            " [-1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]\n",
            " [ 1.]]\n",
            "Estimacion empirica de la media de x =  [[0.1]]\n",
            "Estimacion empirica de la media de x con np.mean =  [0.1]\n"
          ]
        }
      ],
      "source": [
        "# Estimacion empirica de los valores esperados y matriz varianza-covarianza\n",
        "# m es en numero de datos\n",
        "\n",
        "m = 100\n",
        "X = np.zeros((m,1))\n",
        "One = np.ones((m,1))\n",
        "\n",
        "Z = np.random.rand(m,1)\n",
        "\n",
        "# Generacion de datos:\n",
        "for i in range(m):\n",
        "    if Z[i,0] < p0:\n",
        "        X[i,0] = x0\n",
        "    else:\n",
        "        X[i,0] = x1\n",
        "print(\"Datos empiricos de x = \\n\", X[:10]) # los primeros 10\n",
        "\n",
        "Ex_emp = np.dot(One.T,X)/m # probar que esta forma vectorizada estima la media de x\n",
        "print(\"Estimacion empirica de la media de x = \", Ex_emp)\n",
        "\n",
        "Mx = np.mean(X, axis=0) # esta operacion hace lo mismo que Ex_emp\n",
        "print(\"Estimacion empirica de la media de x con np.mean = \", Mx)\n",
        "\n",
        "# jugar con el valor de m y ver como converge Ex_emp a Ex cuando m se hace grande (error ~ 1 / sqrt(m))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb9792ce",
      "metadata": {
        "id": "cb9792ce",
        "outputId": "093fb7bc-8b7e-47db-9820-1dd95228cedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "XM.shape =  (100, 1)\n",
            "Vx_emp =  [[0.99]]\n",
            "Verror = Vx - Vx_emp =  [[0.01]]\n"
          ]
        }
      ],
      "source": [
        "# \"centrar\" los datos\n",
        "XM = X - np.mean(X, axis=0) # esto es Python 'broadcasting'\n",
        "print(\"XM.shape = \", XM.shape)\n",
        "\n",
        "# probar que esta forma vectorizada genera la estimacion empirica de la varianza\n",
        "Vx_emp = np.dot(XM.T,XM)/m # estrictamente deberia dividir por (m-1), por que es irrelevante cuando m es grande?\n",
        "\n",
        "Verror = Vx - Vx_emp # error de estimacion\n",
        "\n",
        "print(\"Vx_emp = \", Vx_emp)\n",
        "print(\"Verror = Vx - Vx_emp = \", Verror)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01df2a1e",
      "metadata": {
        "id": "01df2a1e",
        "outputId": "feb010f7-57d4-45ad-ed80-d35bf82f15a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "p11 = 0.2\n"
          ]
        }
      ],
      "source": [
        "'''probabilidades: 2 variables aleatorias \"x, y\"'''\n",
        "\n",
        "# joint probability distribution of the random variables x and y\n",
        "\n",
        "p00 = 0.1 # = p(x0,y0)\n",
        "p01 = 0.4 # = p(x0,y1)\n",
        "p10 = 0.3 # = p(x1,y0)\n",
        "p11 = 1.0 - p00 - p01 - p10 # = p(x1,y1) # Chequear que no de negativo!\n",
        "print(\"p11 =\", p11)\n",
        "\n",
        "# values of the random variables\n",
        "x0 = -1.\n",
        "x1 = 1.\n",
        "y0 = -1.\n",
        "y1 = 1.\n",
        "\n",
        "# Marginal probability distributions\n",
        "\n",
        "px0 = p00 + p01\n",
        "px1 = p10 + p11\n",
        "\n",
        "py0 = p00 + p10\n",
        "py1 = p01 + p11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c20a2fc8",
      "metadata": {
        "id": "c20a2fc8",
        "outputId": "b1712c9b-fd9a-48a5-9759-a3860ff512f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "E(x) =  0.0\n",
            "E(y) =  0.20000000000000007\n",
            "[0.  0.2]\n",
            "E(xx) =  1.0\n",
            "E(yy) =  1.0\n",
            "E(xy) =  -0.4000000000000001\n",
            "Var(x) =  1.0\n",
            "Var(y) =  0.96\n",
            "CoVar(x,y) =  -0.4000000000000001\n",
            "Matriz Varianza-Covarianza exacta = \n",
            " [[ 1.   -0.4 ]\n",
            " [-0.4   0.96]]\n"
          ]
        }
      ],
      "source": [
        "# Valores esperados y varianza-covarianza exactos\n",
        "Ex = x0*px0 + x1*px1\n",
        "Ey = y0*py0 + y1*py1\n",
        "print(\"E(x) = \", Ex)\n",
        "print(\"E(y) = \", Ey)\n",
        "M_exact = np.array([Ex,Ey])\n",
        "print(M_exact)\n",
        "\n",
        "Exx = x0*x0*px0 + x1*x1*px1\n",
        "Eyy = y0*y0*py0 + y1*y1*py1\n",
        "print(\"E(xx) = \", Exx)\n",
        "print(\"E(yy) = \", Eyy)\n",
        "\n",
        "Exy = x0*y0*p00 + x0*y1*p01 + x1*y0*p10 + x1*x1*p11\n",
        "# Notar que aca es necesario usar la joint probability distribution, las marginales no tienen la informacion necesaria\n",
        "print(\"E(xy) = \", Exy)\n",
        "\n",
        "Vxx = Exx - Ex**2\n",
        "Vyy = Eyy - Ey**2\n",
        "Vxy = Exy - Ex*Ey\n",
        "print(\"Var(x) = \", Vxx)\n",
        "print(\"Var(y) = \", Vyy)\n",
        "print(\"CoVar(x,y) = \", Vxy)\n",
        "\n",
        "VC_exact = np.array([[Vxx,Vxy],[Vxy,Vyy]])\n",
        "print(\"Matriz Varianza-Covarianza exacta = \\n\", VC_exact)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7958151",
      "metadata": {
        "id": "e7958151"
      },
      "source": [
        "Reemplazando las probabilidades marginales por su expresión en termino de las \"joint\", encontrar la expresión para las distintas expresiones en la celta de mas arriba. Notar que cuando queremos calcular términos cruzados, como E(xy) o CoVar(x,y), las marginales no alcanzan y hay que apelar si o si a la joint probability distributions (notar que las marginales tienen 2 parámetros libres mientras que la joint 3)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b567451e",
      "metadata": {
        "id": "b567451e",
        "outputId": "1d31044b-9195-4cf5-a8e4-557bc71d610f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean(X,Y) =  [0.  0.2]\n",
            "Error(Mean) = M_exact - M_emp = \n",
            " [0.00000000e+00 5.55111512e-17]\n",
            "DM.shape =  (100, 2)\n",
            "Mean de DM =  [ 0.00000000e+00 -3.99680289e-17]\n",
            "Matriz Varianza-Covarianza empirica = \n",
            " [[ 1.   -0.36]\n",
            " [-0.36  0.96]]\n",
            "Error(VC) = VC_exact - VC_emp = \n",
            " [[ 0.00000000e+00 -4.00000000e-02]\n",
            " [-4.00000000e-02  2.22044605e-16]]\n"
          ]
        }
      ],
      "source": [
        "# Estimacion empirica de los valores esperados y matriz varianza-covarianza\n",
        "# m es en numero de datos\n",
        "\n",
        "m = 100\n",
        "X = np.zeros((m,1))\n",
        "Y = np.zeros((m,1))\n",
        "\n",
        "Z = np.random.rand(m,1)\n",
        "\n",
        "# Generacion de datos:\n",
        "for i in range(m):\n",
        "    if Z[i,0] < p00:\n",
        "        X[i,0] = x0\n",
        "        Y[i,0] = y0\n",
        "    elif Z[i,0] < p00 + p01:\n",
        "        X[i,0] = x0\n",
        "        Y[i,0] = y1\n",
        "    elif Z[i,0] < p00 + p01 + p10:\n",
        "        X[i,0] = x1\n",
        "        Y[i,0] = y0\n",
        "    else:\n",
        "        X[i,0] = x1\n",
        "        Y[i,0] = y1\n",
        "\n",
        "# Matrix de datos:\n",
        "D = np.concatenate((X, Y), axis=1)\n",
        "\n",
        "#restandole la media tanto a X como a Y\n",
        "M = np.mean(D, axis=0)\n",
        "print(\"Mean(X,Y) = \", M)\n",
        "# Diferencia entre los means exacta y empiricos\n",
        "print(\"Error(Mean) = M_exact - M_emp = \\n\", M_exact - M)\n",
        "\n",
        "\n",
        "\n",
        "DM = D - M  # DM es la matriz de datos \"centrados\".\n",
        "# Notar que a un array de shape (m,2) le restamos uno de shape (2,). Python interpreta corractamente lo que\n",
        "# queremos hacer. Esto se llama \"Broadcasting\"\n",
        "print(\"DM.shape = \", DM.shape)\n",
        "\n",
        "# Chequeamos que los datos en DM estan \"centrados\"\n",
        "print (\"Mean de DM = \", np.mean(DM, axis=0))\n",
        "\n",
        "# Calculamos la matrix Varianza-Covarianza (probar que este es, efectivamente, dicha matriz):\n",
        "VC_emp = (1/m)*np.dot(DM.T,DM)\n",
        "print(\"Matriz Varianza-Covarianza empirica = \\n\", VC_emp)\n",
        "\n",
        "# Diferencia entre la matriz varianza covarianza exacta y la empirica\n",
        "print(\"Error(VC) = VC_exact - VC_emp = \\n\", VC_exact - VC_emp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b73fda9b",
      "metadata": {
        "id": "b73fda9b"
      },
      "source": [
        "En la celda anterior, jugar con el número de datos $m$ para ver como $M_{emp}$ y $VC_{emp}$ van convergiendo a $M_{exact}$ y $VC_{exact}$ cuando $m$ crece. El error debería decrecer como$$\\sim \\frac{1}{\\sqrt{m}}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64d932d5",
      "metadata": {
        "id": "64d932d5"
      },
      "source": [
        "La matriz VC\\_emp, siendo simétrica, tiene que tener autovalores y autovectores reales. Probar que además los autovalores son semidefinidos positivos (es decir, o bien son todos positivos, o algunos pueden ser 0, pero ninguno puede ser negativo).\n",
        "\n",
        "Hint: Para el vector genérico$$ \\mathbf{x} =\n",
        "\\left(\n",
        "   \\begin{array}{c}\n",
        "       x \\\\\n",
        "       y \\\\\n",
        "   \\end{array}\n",
        "\\right)$$\n",
        "usar la propiedad asociativa y la traspuesta de un producto para mostrar que la forma cuadratica$$\\mathbf{x}^{\\top} \\left( VC_{emp} \\right) \\mathbf{x} = \\mathbf{x}^{\\top} \\left( DM^{\\top} DM \\right) \\mathbf{x}$$\n",
        "es necesariamente semidefinida positiva. Que condición se tiene que dar para que para algún vector $\\mathbf{x}$ no nulo$$\n",
        "\\mathbf{x}^{\\top} \\left( DM^{\\top} DM \\right) \\mathbf{x} = \\mathbf{0}?$$\n",
        "Comprobemos numéricamente que la matriz varianza-covarianza tiene autovalores no negativos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e5df563",
      "metadata": {
        "id": "9e5df563",
        "outputId": "93698b9d-c280-4ada-bc83-dc7264f8eb2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "autovalores de VC_emp =  [0.57425837 1.22496071]\n",
            "autovectores de VC_emp = \n",
            " [[ 0.63761414 -0.7703559 ]\n",
            " [-0.7703559  -0.63761414]]\n"
          ]
        }
      ],
      "source": [
        "w , U = LA.eigh(VC_emp) # Notar que uso LA.eigh, con \"h\" al final. Esto conviene para matrices simetricas\n",
        "print(\"autovalores de VC_emp = \", w)\n",
        "print(\"autovectores de VC_emp = \\n\", U)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cef95de",
      "metadata": {
        "id": "9cef95de"
      },
      "source": [
        "Recordemos que las columnas de $U$ son los autovectores de VC\\_emp,$$U = \\left(\n",
        "         \\begin{array}{cc}\n",
        "             | & | \\\\\n",
        "             \\mathbf{v}_0 & \\mathbf{v}_1 \\\\\n",
        "             | & | \\\\\n",
        "         \\end{array}\n",
        "      \\right), \\quad VC_{emp} \\mathbf{v}_0 = \\lambda_0 \\mathbf{v}_1,\n",
        "      \\quad VC_{emp} \\mathbf{v}_0 = \\lambda_0 \\mathbf{v}_1$$ y por ser VC\\_emp simetrica, la matriz $U$ es ortonormal, es decir, sus columnas, los vectores $\\mathbf{v}_0$ y $\\mathbf{v}_1$, forman una base ortonormal, por lo que $U U^{\\top} = U^{\\top} U = I$). Entonces, tal como lo hicimos en un HW pasado,$$\\mathbf{x}^{\\top} VC_{emp} \\mathbf{x} = \\mathbf{x}^{\\top} U \\left( U^{\\top} VC_{emp} U \\right) U^{\\top} \\mathbf{x}$$\n",
        "Donde$$U^{\\top} VC_{emp} U$$\n",
        "es una matriz diagonal cuyos elementos diagonales son los autovalores de VC\\_emp, y$$U^{\\top} \\mathbf{x}$$\n",
        "son las coordenadas del vector $\\mathbf{x}$ en la base $\\{ \\mathbf{v}_0, \\mathbf{v}_1 \\}$ de autovectores de\n",
        "VC\\_emp. Comprobemos esto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7639e6e3",
      "metadata": {
        "id": "7639e6e3",
        "outputId": "1590b632-3e6e-4634-88dc-8940e1b0645d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "U^T VC_emp U = \n",
            " [[0.5743 0.    ]\n",
            " [0.     1.225 ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"U^T VC_emp U = \\n\", np.round(np.dot(U.T,np.dot(VC_emp, U)),4))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ada6ebf2",
      "metadata": {
        "id": "ada6ebf2"
      },
      "source": [
        "Esto significa que si en cambio de las variables aleatorias $x$ e $y$, que, recordemos, podían tomar valores $x_0, x_1$ y\n",
        "$y_0, y_1$ respectivamente, usamos las combinaciones lineales:\n",
        "$$p = \\mathbf{v}_{0}^{\\top}\\mathbf{x} = (v_{00}, v_{01})\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      x \\\\\n",
        "      y \\\\\n",
        "    \\end{array}\n",
        "\\right) = v_{00}x + v_{01} y, \\qquad\n",
        "q = \\mathbf{v}_{1}^{\\top}\\mathbf{x} = (v_{10}, v_{11})\n",
        "\\left(\n",
        "    \\begin{array}{c}\n",
        "      x \\\\\n",
        "      y \\\\\n",
        "    \\end{array}\n",
        "\\right) = v_{10}x + v_{11} y$$\n",
        "entonces, las variables aleatorias $p$ y $q$ van a tener correlación nula, es decir, sus covarianzas van a ser cero. Notar que $p$ nos da la proyección de $\\mathbf{x}$ sobre $\\mathbf{v}_{0}$ y $q$ la proyección de $\\mathbf{x}$ sobre $\\mathbf{v}_{1}$."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6bb2fb6",
      "metadata": {
        "id": "c6bb2fb6"
      },
      "source": [
        "Vamos a comprobar todo esto numéricamente, pero como ya sabemos mucha algebra lineal es MUY útil ser lo mas compacto posible en nuestras operaciones matriciales y vectoriales, no solo por simplicidad, sino porque además Python, cuando puede paraleliza los cálculos, haciéndolos muchísimo más rápidos. Pero solo los puede paralelizar si están escritos en forma matricial.\n",
        "\n",
        "Fijémonos que por ser $\\mathbf{v}_{i}$ y $\\mathbf{x}$ vectores, sus productos escalares conmutan, es decir:$$p = \\mathbf{v}_{0}^{\\top}\\mathbf{x} = v_{00}x + v_{01} y =\n",
        "\\mathbf{x}^{\\top}\\mathbf{v}_{0}, \\qquad\n",
        "q = \\mathbf{v}_{1}^{\\top}\\mathbf{x} = v_{10}x + v_{11} y=\n",
        "\\mathbf{x}^{\\top}\\mathbf{v}_{1}$$\n",
        "En la matriz $DM$, de datos \"centrados\", la fila iésima corresponde al dato $i$ traspuesto:$$\n",
        "\\mathbf{x}^{\\top}_i = ( x_i - \\bar{x}, y_i - \\bar{y})$$\n",
        "Entonces:$$PQ = DM \\cdot U = \\left(\n",
        "    \\begin{array}{c}\n",
        "       \\mathbf{x}^{\\top}_0 \\\\\n",
        "       \\vdots \\\\\n",
        "       \\mathbf{x}^{\\top}_m \\\\\n",
        "    \\end{array}\n",
        "  \\right) (\\mathbf{v}_0, \\mathbf{v}_1)=\n",
        "  \\left(\n",
        "    \\begin{array}{cc}\n",
        "      \\mathbf{x}^{\\top}_0 \\mathbf{v}_0 & \\mathbf{x}^{\\top}_0 \\mathbf{v}_1  \\\\\n",
        "      \\vdots & \\vdots \\\\\n",
        "      \\mathbf{x}^{\\top}_m \\mathbf{v}_0 & \\mathbf{x}^{\\top}_m \\mathbf{v}_1 \\\\\n",
        "    \\end{array}\n",
        "  \\right)$$\n",
        "Es decir, $PQ$ es una matriz de $m \\times 2$ cuya primera columna son los datos empíricos de la variable aleatoria $p$ y su segunda columna son los datos empíricos de la variable aleatoria $q$.\n",
        "\n",
        "Además, como dijimos, el elemento $p_i$ de la primera columna es la proyección, en el plano $(x,y)$, del dato empírico $(x_i,y_i)$ en la dirección del subespacio generado por $\\mathbf{v}_0$, y el elemento $q_i$ de la segunda columna es la proyección, en el plano $(x,y)$, del dato empírico $(x_i,y_i)$ en la dirección del subespacio generado por $\\mathbf{v}_1$.\n",
        "\n",
        "Argumentamos antes que estas nuevas variables deberían tener covarianza cero. Comprobemoslo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c88abb5",
      "metadata": {
        "id": "9c88abb5",
        "outputId": "ac05b158-6c7e-4662-f4a2-35e3ec9b3c3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PQ.shape =  (1000000, 2)\n",
            "matriz varianza-covarianza de las variables p y q = \n",
            " [[ 0.574 -0.   ]\n",
            " [-0.     1.225]]\n"
          ]
        }
      ],
      "source": [
        "PQ = np.dot(DM,U)\n",
        "print(\"PQ.shape = \", PQ.shape)\n",
        "\n",
        "VC_PQ = (1/m)*np.dot(PQ.T,PQ)\n",
        "print(\"matriz varianza-covarianza de las variables p y q = \\n\", np.round(VC_PQ,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0275ac6f",
      "metadata": {
        "id": "0275ac6f"
      },
      "source": [
        "Notar que, efectivamente, no solo los elementos no diagonales son cero, sino que, además, los diagonales son iguales a los autovalores de la matriz varianza covarianza VC\\_emp de los datos empíricos originales $x$ e $y$!\n",
        "\n",
        "Esto es como debía ser, ya que, como vimos antes, $$\\mathbf{x}^{\\top} VC_{emp} \\mathbf{x} = \\mathbf{x}^{\\top} U \\left( U^{\\top} VC_{emp} U \\right) U^{\\top} \\mathbf{x}$$\n",
        "Donde$$U^{\\top} VC_{emp} U$$\n",
        "es una matriz diagonal cuyos elementos diagonales son los autovalores de VC\\_emp, y$$U^{\\top} \\mathbf{x}$$\n",
        "son las coordenadas del vector $\\mathbf{x}$ en la base $\\{ \\mathbf{v}_0, \\mathbf{v}_1 \\}$ de autovectores de VC\\_emp."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a284733c",
      "metadata": {
        "id": "a284733c"
      },
      "source": [
        "Todo esto vale independientemente dela dimensionalidad de los datos. Si en vez de $d=2$ tenemos un $d$ (número de \"features\") genérico, la matriz de datos ser de $m \\times d$, la matriz VarCov será de $d \\times d$, esta también será simétricas y semidefinida positiva, y si pasamos a la base de autovectores, las variables aleatorias correspondientes a las proyecciones sobre los autovectores no tendrán correlación entre ellas (sus covarianzas serán cero), y además sus varianzas serán los autovalores de la matriz varianza-covarianza original."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Punto 3**\n",
        "\n",
        "Generar un Jupyter notebook similar, pero en el que la variable aleatoria X puede tener 3 valores diferentes (x0, x1, x2) e Y cuatro valores diferentes (y0, y1, y2, y3). Pero antes de eso explicar por qué el número de eventos diferentes es 12, y por lo tanto la distribución de probabilidades conjunta tiene 12 probabilidades diferentes pij, i=0,1,2, j=0,1,2,3 (de las cuales 11 son independientes, y la doceava tiene que ser tal que la suma de las 12 de 1 (y todas sean positivas). Notar que la matriz varianza covarianza sigue siendo de 2x2, porque hay dos variables aleatorias."
      ],
      "metadata": {
        "id": "ws334K44F7fu"
      },
      "id": "ws334K44F7fu"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definir los valores posibles\n",
        "x_vals = np.array([0, 1, 2])    # x0, x1, x2\n",
        "y_vals = np.array([0, 1, 2, 3]) # y0, y1, y2, y3\n"
      ],
      "metadata": {
        "id": "wyZzZy6mGKKD"
      },
      "id": "wyZzZy6mGKKD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Distribución conjunta de ejemplo - Generamos una matriz 3×4 de valores aleatorios y la normalizamos.\n",
        "\n",
        "P = np.random.rand(len(x_vals), len(y_vals))\n",
        "P = P / P.sum()  # Normalizar a suma 1\n",
        "print(\"Distribución conjunta P:\")\n",
        "print(P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJmtXUqlGzbc",
        "outputId": "eb4a97f1-bd6b-46a5-85b1-52d3ee66b40d"
      },
      "id": "jJmtXUqlGzbc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución conjunta P:\n",
            "[[0.02956629 0.13923808 0.0564028  0.05831484]\n",
            " [0.05747919 0.15613068 0.14529197 0.11599674]\n",
            " [0.05612531 0.02214805 0.1209679  0.04233816]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Distribuciones marginales\n",
        "# - p_X(i) = Σ_j P[i,j]\n",
        "# - p_Y(j) = Σ_i P[i,j]\n",
        "\n",
        "# Marginal de X (suma por filas)\n",
        "p_x = P.sum(axis=1)\n",
        "# Marginal de Y (suma por columnas)\n",
        "p_y = P.sum(axis=0)\n",
        "\n",
        "print(\"\\nMarginal de X:\", p_x)\n",
        "print(\"Marginal de Y:\", p_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rT71lJqHG5Vp",
        "outputId": "6086305e-8e34-4088-99aa-0039e3dc448a"
      },
      "id": "rT71lJqHG5Vp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Marginal de X: [0.283522   0.47489859 0.24157942]\n",
            "Marginal de Y: [0.14317079 0.31751681 0.32266267 0.21664973]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Cálculo de esperanzas\n",
        "\n",
        "# E[X] = Σ_i x_i p_X(i)\n",
        "# E[Y] = Σ_j y_j p_Y(j)\n",
        "\n",
        "\n",
        "E_X = np.dot(x_vals, p_x)\n",
        "E_Y = np.dot(y_vals, p_y)\n",
        "print(f\"E[X] = {E_X:.4f}\")\n",
        "print(f\"E[Y] = {E_Y:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHS4x-01G9oJ",
        "outputId": "5b217644-be1d-4c04-e934-63034515f7b3"
      },
      "id": "BHS4x-01G9oJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E[X] = 0.9581\n",
            "E[Y] = 1.6128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Cálculo de varianzas\n",
        "# Var(X) = Σ_i (x_i - E[X])^2 p_X(i)\n",
        "# Var(Y) = Σ_j (y_j - E[Y])^2 p_Y(j)\n",
        "\n",
        "Var_X = np.dot((x_vals - E_X)**2, p_x)\n",
        "Var_Y = np.dot((y_vals - E_Y)**2, p_y)\n",
        "print(f\"Var(X) = {Var_X:.4f}\")\n",
        "print(f\"Var(Y) = {Var_Y:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MLs_BZ-HBTG",
        "outputId": "b5a52575-871e-402e-86a0-0eccae21c788"
      },
      "id": "6MLs_BZ-HBTG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(X) = 0.5233\n",
            "Var(Y) = 0.9569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#7. Cálculo de la covarianza\n",
        "\n",
        "# Cov(X,Y) = E[XY] - E[X]E[Y], donde\n",
        "# E[XY] = Σ_i Σ_j x_i y_j P[i,j]\n",
        "\n",
        "# E[XY]\n",
        "E_XY = sum(x * y * P[i, j] for i, x in enumerate(x_vals) for j, y in enumerate(y_vals))\n",
        "Cov_XY = E_XY - E_X * E_Y\n",
        "print(f\"Cov(X,Y) = {Cov_XY:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oc8Ogc0EHE-0",
        "outputId": "709a0a17-7650-441e-d5a0-32033447b97b"
      },
      "id": "Oc8Ogc0EHE-0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cov(X,Y) = 0.0318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Matriz varianza–covarianza\n",
        "\n",
        "# Construimos la matriz 2×2 - Notar que la matriz varianza covarianza sigue siendo de 2x2, porque hay dos variables aleatorias.\n",
        "\n",
        "Sigma = np.array([[Var_X, Cov_XY], [Cov_XY, Var_Y]])\n",
        "print(\"\\nMatriz Var–Cov:\")\n",
        "print(Sigma)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ1PCCmZHI4U",
        "outputId": "f9c17758-77c2-43cf-fc0d-e66db54d7881"
      },
      "id": "bZ1PCCmZHI4U",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Matriz Var–Cov:\n",
            "[[0.52334223 0.03175477]\n",
            " [0.03175477 0.95691915]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Punto 4**\n",
        "\n",
        "Generar un Jupyter notebook similar, pero con 3 variables aleatorias, X, Y, Z, cada una de las cuales puede tomas dos valores diferentes. Pero antes de eso explicar por qué el número de eventos diferentes es 8 y por lo tanto la distribución de probabilidades conjunta tiene 8 probabilidades diferentes pijk, i=0,1, j=0,1, k=0,1 (de las cuales 7 son independientes, y la octava tiene que ser tal que la suma de las 8 de 1 (y todas sean positivas). Notar que la matriz varianza covarianza ahora es de 3x3, porque hay tres variables aleatorias"
      ],
      "metadata": {
        "id": "dDIA5rcVHc_4"
      },
      "id": "dDIA5rcVHc_4"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Definir los valores posibles para cada variable\n",
        "x_vals = np.array([0, 1])\n",
        "y_vals = np.array([0, 1])\n",
        "z_vals = np.array([0, 1])"
      ],
      "metadata": {
        "id": "vJnZPyS6Jdgm"
      },
      "id": "vJnZPyS6Jdgm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Generar distribución conjunta aleatoria y normalizar\n",
        "P = np.random.rand(2, 2, 2)\n",
        "P /= P.sum()\n",
        "print(\"Distribución conjunta P:\", P)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9Ebq8JjJkEa",
        "outputId": "ef0c0e51-09f8-42ed-fe9f-0e5aa2862470"
      },
      "id": "V9Ebq8JjJkEa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribución conjunta P: [[[0.17524946 0.15783242]\n",
            "  [0.16183824 0.11335305]]\n",
            "\n",
            " [[0.15583243 0.07961889]\n",
            "  [0.02664769 0.12962782]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Calcular distribuciones marginales\n",
        "p_x = P.sum(axis=(1, 2))  # marginal de X\n",
        "p_y = P.sum(axis=(0, 2))  # marginal de Y\n",
        "p_z = P.sum(axis=(0, 1))  # marginal de Z\n",
        "print(\"Marginal X:\", p_x)\n",
        "print(\"Marginal Y:\", p_y)\n",
        "print(\"Marginal Z:\", p_z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PxIaJpsJl4k",
        "outputId": "eb504e9f-d632-4563-f56e-05d4f8761ded"
      },
      "id": "7PxIaJpsJl4k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marginal X: [0.60827316 0.39172684]\n",
            "Marginal Y: [0.56853321 0.43146679]\n",
            "Marginal Z: [0.51956782 0.48043218]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Calcular esperanzas\n",
        "E_X = np.dot(x_vals, p_x)\n",
        "E_Y = np.dot(y_vals, p_y)\n",
        "E_Z = np.dot(z_vals, p_z)\n",
        "print(f\"E[X] = {E_X:.4f}\")\n",
        "print(f\"E[Y] = {E_Y:.4f}\")\n",
        "print(f\"E[Z] = {E_Z:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYHduO2hJn-n",
        "outputId": "56735ef0-b1a6-4023-c0d2-95a5c9c79eed"
      },
      "id": "hYHduO2hJn-n",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E[X] = 0.3917\n",
            "E[Y] = 0.4315\n",
            "E[Z] = 0.4804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Calcular varianzas\n",
        "Var_X = np.dot((x_vals - E_X)**2, p_x)\n",
        "Var_Y = np.dot((y_vals - E_Y)**2, p_y)\n",
        "Var_Z = np.dot((z_vals - E_Z)**2, p_z)\n",
        "print(f\"Var(X) = {Var_X:.4f}\")\n",
        "print(f\"Var(Y) = {Var_Y:.4f}\")\n",
        "print(f\"Var(Z) = {Var_Z:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lb4XfLSyJrE8",
        "outputId": "1a659c84-0af7-40de-e4fb-7ba7fd00e615"
      },
      "id": "Lb4XfLSyJrE8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Var(X) = 0.2383\n",
            "Var(Y) = 0.2453\n",
            "Var(Z) = 0.2496\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Calcular covarianzas --  E[XY] = Σ x_i y_j P[i,j,k] (suma sobre k)\n",
        "E_XY = sum(x * y * P[i, j, k]\n",
        "            for i, x in enumerate(x_vals)\n",
        "            for j, y in enumerate(y_vals)\n",
        "            for k in range(len(z_vals)))\n",
        "E_XZ = sum(x * z * P[i, j, k]\n",
        "            for i, x in enumerate(x_vals)\n",
        "            for j in range(len(y_vals))\n",
        "            for k, z in enumerate(z_vals))\n",
        "E_YZ = sum(y * z * P[i, j, k]\n",
        "            for i in range(len(x_vals))\n",
        "            for j, y in enumerate(y_vals)\n",
        "            for k, z in enumerate(z_vals))\n",
        "\n",
        "Cov_XY = E_XY - E_X * E_Y\n",
        "Cov_XZ = E_XZ - E_X * E_Z\n",
        "Cov_YZ = E_YZ - E_Y * E_Z\n",
        "print(f\"Cov(X,Y) = {Cov_XY:.4f}\")\n",
        "print(f\"Cov(X,Z) = {Cov_XZ:.4f}\")\n",
        "print(f\"Cov(Y,Z) = {Cov_YZ:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kEtXX9BJtDg",
        "outputId": "06e05d5b-47c0-49d0-d6bf-bf221c0f623f"
      },
      "id": "3kEtXX9BJtDg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cov(X,Y) = -0.0127\n",
            "Cov(X,Z) = 0.0210\n",
            "Cov(Y,Z) = 0.0357\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}